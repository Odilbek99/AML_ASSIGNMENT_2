{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AML ASSIGNMENT 2\n",
        "- Advanced Machine Learning, Innopolis University \n",
        "- Professor: Witold Pedrycz\n",
        "- Teaching Assistant: Gcinizwe Dlamini\n",
        "\n",
        "Task Description: [here](https://hackmd.io/@gFZmdMTOQxGFHEFqqU8pMQ/Hk7A_FIRO#Labelling-logic)\n",
        "\n",
        "Dataset:[Task 1](https://drive.google.com/file/d/1iVl4Q4Bq3Fbwv60lLthfBc6eYxYLrdnU/view?usp=sharing) & [Task 2](https://cloudstor.aarnet.edu.au/plus/s/2DhnLGDdEECo4ys?path=%2FUNSW-NB15%20-%20CSV%20Files%2Fa%20part%20of%20training%20and%20testing%20set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6UIbGBBybkFS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "geoTW8PybkC0"
      },
      "outputs": [],
      "source": [
        "identity_data = pd.read_csv(\"data_identity.csv\")\n",
        "transaction_data = pd.read_csv(\"data_transaction.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KXG6PalbkAR",
        "outputId": "2b5aa0cd-b44d-4fbb-ec4a-0e2d147f79ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transaction data categorical features: Index(['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', 'M1',\n",
            "       'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9'],\n",
            "      dtype='object')\n",
            "\n",
            "Identity data categorical features: Index(['id_12', 'id_15', 'id_16', 'id_23', 'id_27', 'id_28', 'id_29', 'id_30',\n",
            "       'id_31', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38',\n",
            "       'DeviceType', 'DeviceInfo'],\n",
            "      dtype='object')\n",
            "\n"
          ]
        }
      ],
      "source": [
        "obj_transaction_data = transaction_data.select_dtypes([\"object\"]).columns\n",
        "obj_identity_data = identity_data.select_dtypes([\"object\"]).columns\n",
        "\n",
        "print(f'Transaction data categorical features: {transaction_data.select_dtypes([\"object\"]).columns}\\n')\n",
        "print(f'Identity data categorical features: {identity_data.select_dtypes([\"object\"]).columns}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kA0JFp0fbj9h"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encoding categorical features using LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "identity_data[obj_identity_data] = identity_data[obj_identity_data].apply(le.fit_transform)\n",
        "transaction_data[obj_transaction_data] = transaction_data[obj_transaction_data].apply(le.fit_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifuDTJdKbj6p",
        "outputId": "0a022a85-e9e3-40c4-d620-20a415ed6b58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index([], dtype='object')\n",
            "Index([], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(transaction_data.select_dtypes([\"object\"]).columns)\n",
        "print(identity_data.select_dtypes([\"object\"]).columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "transaction_notnan_df = transaction_data.notna()\n",
        "identity_notnan_df = identity_data.notna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "f1JAyjTlbj3M"
      },
      "outputs": [],
      "source": [
        "full_data = transaction_data.join(identity_data.set_index(\"TransactionID\"), on=\"TransactionID\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ASOGIeZCbjvG"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "# Data normalizing using RobustScaler\n",
        "\n",
        "transformer = RobustScaler().fit_transform(full_data.fillna(0).values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCanceled future for execute_request message before replies were done"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "data_notnan_df = full_data.notna()\n",
        "data_n = data_notnan_df.astype(\"int\").values\n",
        "data = np.concatenate([transformer, data_n], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CaWMdNc9ANkx"
      },
      "outputs": [],
      "source": [
        "robust_df = pd.DataFrame(transformer, columns=full_data.columns)\n",
        "X = robust_df.drop(columns=['isFraud','TransactionID'])\n",
        "y = robust_df['isFraud']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WH5ilWwxANf7"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "dDwy3MxiANbk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dxTgnaw_ANYg"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "\n",
        "# convert to tensors\n",
        "X_train_ten = torch.Tensor(X_train.values)\n",
        "X_test_ten = torch.Tensor(X_test.values)\n",
        "y_train_ten = torch.Tensor(y_train.values)\n",
        "y_test_ten = torch.Tensor(y_test.values)\n",
        "\n",
        "# create DataLoaders\n",
        "train_loader = DataLoader(TensorDataset(X_train_ten, y_train_ten), batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(X_test_ten, y_test_ten), batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlQ1ZzocM0UC",
        "outputId": "a00e9b08-6b89-482b-defc-1c3af0983210"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128, 432])\n"
          ]
        }
      ],
      "source": [
        "for x,_ in train_loader:\n",
        "  print(x.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "f2PDIa8GJkrK"
      },
      "outputs": [],
      "source": [
        "## modified undercomplete AE from the lab\n",
        "class under_autoencoder(nn.Module):\n",
        "    def __init__(self, input_size, latent_dim):\n",
        "      super(under_autoencoder, self).__init__()\n",
        "      # Step 1 : Define the encoder \n",
        "      # Step 2 : Define the decoder\n",
        "      # Step 3 : Initialize the weights (optional)\n",
        "      self.encoder = nn.Sequential(\n",
        "          nn.Linear(input_size, input_size//2),\n",
        "          nn.ReLU(True),\n",
        "          nn.Linear(input_size//2, input_size//3),\n",
        "          nn.Linear(input_size//3, input_size//4),\n",
        "          nn.Tanh(),\n",
        "          nn.Linear(input_size//4, latent_dim)\n",
        "      )\n",
        "      # the output size of the decoder should be twice smaller than the input size to the encoder\n",
        "      self.decoder = nn.Sequential(\n",
        "          nn.Linear(latent_dim, input_size//4),\n",
        "          nn.ReLU(True),\n",
        "          nn.Linear(input_size//4, input_size//3),\n",
        "          nn.Tanh(),\n",
        "          nn.Linear(input_size//3, input_size//2)\n",
        "      )\n",
        "      self.encoder.apply(self.__init_weights)\n",
        "      self.decoder.apply(self.__init_weights)\n",
        "        \n",
        "    def forward(self, x):\n",
        "      # Step 1: Pass the input through encoder to get latent representation\n",
        "      # Step 2: Take latent representation and pass through decoder\n",
        "      x = self.encoder(x)\n",
        "      x = self.decoder(x)\n",
        "      return x\n",
        "        \n",
        "    \n",
        "    def encode(self,input):\n",
        "      #Step 1: Pass the input through the encoder to get latent representation\n",
        "      return self.encoder(input)\n",
        "    \n",
        "    def decode(self, input):\n",
        "      return self.decoder(input)\n",
        "    \n",
        "    def __init_weights(self,m):\n",
        "      #Init the weights (optional)\n",
        "      if type(m) == nn.Linear:\n",
        "          torch.nn.init.xavier_uniform_(m.weight)\n",
        "          m.bias.data.fill_(0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "GfhaG2IBJkn6"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-4\n",
        "eps = 1e-9\n",
        "\n",
        "AE = under_autoencoder(864,200).to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.RMSprop(AE.parameters(), lr=learning_rate, eps=eps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "b5ILPCwyJkRF",
        "outputId": "f94dedd0-98de-420a-9f8a-053411d8496a"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_4716/4286574450.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m432\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m432\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# the features of X already modified by missing values indicator; only need to modify the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_4716/3890999801.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0;31m# Step 1: Pass the input through encoder to get latent representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0;31m# Step 2: Take latent representation and pass through decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (128x432 and 864x432)"
          ]
        }
      ],
      "source": [
        "num_epochs = 20\n",
        "\n",
        "best_model = AE.state_dict()\n",
        "best_loss = 1e300\n",
        "best_epoch = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  epoch_loss = 0.0\n",
        "  for X, _ in train_loader:\n",
        "    X = X.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    # forward\n",
        "    output = AE(X)\n",
        "    loss = criterion(output * X[:, 432:], X[:, :432]) # the features of X already modified by missing values indicator; only need to modify the output\n",
        "\n",
        "    # backward\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "  # log\n",
        "  print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, num_epochs, epoch_loss / len(train_loader)))\n",
        "  \n",
        "  # test the model\n",
        "  with torch.no_grad():\n",
        "    tot_loss = 0\n",
        "    for X, _ in test_loader:\n",
        "      X = X.to(device)\n",
        "      \n",
        "      output = AE(X)\n",
        "      tot_loss += criterion(output * X[:, 432:], X[:, :432]).item()\n",
        "      \n",
        "    tot_loss = tot_loss / len(test_loader)\n",
        "    \n",
        "    print(\"Test loss:\", tot_loss)\n",
        "      \n",
        "    if tot_loss < best_loss:\n",
        "      best_loss = tot_loss\n",
        "      best_model = AE.state_dict()\n",
        "      best_epoch = epoch\n",
        "    else:\n",
        "      AE.load_state_dict(best_model)\n",
        "      \n",
        "print(f\"The best test loss is {best_loss}, from the epoch number {best_epoch + 1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "aA0LlfbgJkOu",
        "outputId": "cd0dfe1a-b400-4a9b-b109-20e69a4d5b2e"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_4716/1396246067.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_4716/1378832873.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0;31m# Step 1: Pass the input through encoder to get latent representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0;31m# Step 2: Take latent representation and pass through decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (128x432 and 862x431)"
          ]
        }
      ],
      "source": [
        "num_epochs = 20\n",
        "\n",
        "best_model = AE.state_dict()\n",
        "best_loss = 1e300\n",
        "best_epoch = 0\n",
        "for epoch in range(num_epochs):\n",
        "  epoch_loss = 0.0\n",
        "  for X in train_loader:\n",
        "    X = X[0].to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    # forward\n",
        "    output = AE(X)\n",
        "    loss = criterion(output, X)\n",
        "\n",
        "    # backward\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "  # log\n",
        "  print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, num_epochs, loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcRqklooJkMO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_v4hTj_gJkJm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xn6EQ8CJkHL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNTMQnARJkEN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoVG9K5BJj9n"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP3oUn4AEsRI"
      },
      "source": [
        "# Task 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 288,
      "metadata": {
        "id": "xUjMt7TqzIjP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 289,
      "metadata": {
        "id": "eB5xKbUvzqvo"
      },
      "outputs": [],
      "source": [
        "# Dataset loading \n",
        "train = pd.read_csv('/content/drive/MyDrive/Assignment2_AML/Task 2/datasets/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/Assignment2_AML/Task 2/datasets/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 290,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qx0jdjOO474i",
        "outputId": "268f11a2-bf36-4535-cb05-44bc62abf164"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(175341, 45)"
            ]
          },
          "execution_count": 290,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KG_nSt0PH0Uc",
        "outputId": "0cf7df00-d632-418a-8832-28fedb229efb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "WlD7-P7iz_YG",
        "outputId": "ab78c9fc-9e54-46aa-8341-f0989e27b108"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e8ca4450-05eb-4b78-8092-c440d8b234ed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>dur</th>\n",
              "      <th>proto</th>\n",
              "      <th>service</th>\n",
              "      <th>state</th>\n",
              "      <th>spkts</th>\n",
              "      <th>dpkts</th>\n",
              "      <th>sbytes</th>\n",
              "      <th>dbytes</th>\n",
              "      <th>rate</th>\n",
              "      <th>...</th>\n",
              "      <th>ct_dst_sport_ltm</th>\n",
              "      <th>ct_dst_src_ltm</th>\n",
              "      <th>is_ftp_login</th>\n",
              "      <th>ct_ftp_cmd</th>\n",
              "      <th>ct_flw_http_mthd</th>\n",
              "      <th>ct_src_ltm</th>\n",
              "      <th>ct_srv_dst</th>\n",
              "      <th>is_sm_ips_ports</th>\n",
              "      <th>attack_cat</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>udp</td>\n",
              "      <td>-</td>\n",
              "      <td>INT</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>496</td>\n",
              "      <td>0</td>\n",
              "      <td>90909.0902</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>udp</td>\n",
              "      <td>-</td>\n",
              "      <td>INT</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1762</td>\n",
              "      <td>0</td>\n",
              "      <td>125000.0003</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>udp</td>\n",
              "      <td>-</td>\n",
              "      <td>INT</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1068</td>\n",
              "      <td>0</td>\n",
              "      <td>200000.0051</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>udp</td>\n",
              "      <td>-</td>\n",
              "      <td>INT</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>900</td>\n",
              "      <td>0</td>\n",
              "      <td>166666.6608</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>udp</td>\n",
              "      <td>-</td>\n",
              "      <td>INT</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2126</td>\n",
              "      <td>0</td>\n",
              "      <td>100000.0025</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 45 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8ca4450-05eb-4b78-8092-c440d8b234ed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e8ca4450-05eb-4b78-8092-c440d8b234ed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e8ca4450-05eb-4b78-8092-c440d8b234ed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   id       dur proto service state  spkts  dpkts  sbytes  dbytes  \\\n",
              "0   1  0.000011   udp       -   INT      2      0     496       0   \n",
              "1   2  0.000008   udp       -   INT      2      0    1762       0   \n",
              "2   3  0.000005   udp       -   INT      2      0    1068       0   \n",
              "3   4  0.000006   udp       -   INT      2      0     900       0   \n",
              "4   5  0.000010   udp       -   INT      2      0    2126       0   \n",
              "\n",
              "          rate  ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  \\\n",
              "0   90909.0902  ...                 1               2             0   \n",
              "1  125000.0003  ...                 1               2             0   \n",
              "2  200000.0051  ...                 1               3             0   \n",
              "3  166666.6608  ...                 1               3             0   \n",
              "4  100000.0025  ...                 1               3             0   \n",
              "\n",
              "   ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  \\\n",
              "0           0                 0           1           2                0   \n",
              "1           0                 0           1           2                0   \n",
              "2           0                 0           1           3                0   \n",
              "3           0                 0           2           3                0   \n",
              "4           0                 0           2           3                0   \n",
              "\n",
              "   attack_cat  label  \n",
              "0      Normal      0  \n",
              "1      Normal      0  \n",
              "2      Normal      0  \n",
              "3      Normal      0  \n",
              "4      Normal      0  \n",
              "\n",
              "[5 rows x 45 columns]"
            ]
          },
          "execution_count": 292,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CRJLWtUKeJ9"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 293,
      "metadata": {
        "id": "3BYMYTFp0E3h"
      },
      "outputs": [],
      "source": [
        "# Concatinate train and test datasets for data preprocessing\n",
        "\n",
        "full_data = pd.concat([train, test], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 294,
      "metadata": {
        "id": "ctdwIcKC0HBr"
      },
      "outputs": [],
      "source": [
        "# Divide data into x - features, y - labels\n",
        "\n",
        "X = full_data.drop('label', axis=1)\n",
        "y = full_data['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 295,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "lmCcPAe8-NPj",
        "outputId": "a71b79dc-f0c6-439f-b8da-91d5ef5020db"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-00404e39-4a01-4915-82a2-3b236f062514\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>dur</th>\n",
              "      <th>proto</th>\n",
              "      <th>service</th>\n",
              "      <th>state</th>\n",
              "      <th>spkts</th>\n",
              "      <th>dpkts</th>\n",
              "      <th>sbytes</th>\n",
              "      <th>dbytes</th>\n",
              "      <th>rate</th>\n",
              "      <th>...</th>\n",
              "      <th>ct_src_dport_ltm</th>\n",
              "      <th>ct_dst_sport_ltm</th>\n",
              "      <th>ct_dst_src_ltm</th>\n",
              "      <th>is_ftp_login</th>\n",
              "      <th>ct_ftp_cmd</th>\n",
              "      <th>ct_flw_http_mthd</th>\n",
              "      <th>ct_src_ltm</th>\n",
              "      <th>ct_srv_dst</th>\n",
              "      <th>is_sm_ips_ports</th>\n",
              "      <th>attack_cat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>udp</td>\n",
              "      <td>-</td>\n",
              "      <td>INT</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>496</td>\n",
              "      <td>0</td>\n",
              "      <td>90909.0902</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>udp</td>\n",
              "      <td>-</td>\n",
              "      <td>INT</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1762</td>\n",
              "      <td>0</td>\n",
              "      <td>125000.0003</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>udp</td>\n",
              "      <td>-</td>\n",
              "      <td>INT</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1068</td>\n",
              "      <td>0</td>\n",
              "      <td>200000.0051</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>udp</td>\n",
              "      <td>-</td>\n",
              "      <td>INT</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>900</td>\n",
              "      <td>0</td>\n",
              "      <td>166666.6608</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>udp</td>\n",
              "      <td>-</td>\n",
              "      <td>INT</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2126</td>\n",
              "      <td>0</td>\n",
              "      <td>100000.0025</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 44 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-00404e39-4a01-4915-82a2-3b236f062514')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-00404e39-4a01-4915-82a2-3b236f062514 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-00404e39-4a01-4915-82a2-3b236f062514');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   id       dur proto service state  spkts  dpkts  sbytes  dbytes  \\\n",
              "0   1  0.000011   udp       -   INT      2      0     496       0   \n",
              "1   2  0.000008   udp       -   INT      2      0    1762       0   \n",
              "2   3  0.000005   udp       -   INT      2      0    1068       0   \n",
              "3   4  0.000006   udp       -   INT      2      0     900       0   \n",
              "4   5  0.000010   udp       -   INT      2      0    2126       0   \n",
              "\n",
              "          rate  ...  ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  \\\n",
              "0   90909.0902  ...                 1                 1               2   \n",
              "1  125000.0003  ...                 1                 1               2   \n",
              "2  200000.0051  ...                 1                 1               3   \n",
              "3  166666.6608  ...                 2                 1               3   \n",
              "4  100000.0025  ...                 2                 1               3   \n",
              "\n",
              "   is_ftp_login  ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  \\\n",
              "0             0           0                 0           1           2   \n",
              "1             0           0                 0           1           2   \n",
              "2             0           0                 0           1           3   \n",
              "3             0           0                 0           2           3   \n",
              "4             0           0                 0           2           3   \n",
              "\n",
              "   is_sm_ips_ports  attack_cat  \n",
              "0                0      Normal  \n",
              "1                0      Normal  \n",
              "2                0      Normal  \n",
              "3                0      Normal  \n",
              "4                0      Normal  \n",
              "\n",
              "[5 rows x 44 columns]"
            ]
          },
          "execution_count": 295,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwMZhl0p1cNg",
        "outputId": "1369b388-6f68-4f1b-88f8-38eed1cc27ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 257673 entries, 0 to 257672\n",
            "Data columns (total 44 columns):\n",
            " #   Column             Non-Null Count   Dtype  \n",
            "---  ------             --------------   -----  \n",
            " 0   id                 257673 non-null  int64  \n",
            " 1   dur                257673 non-null  float64\n",
            " 2   proto              257673 non-null  object \n",
            " 3   service            257673 non-null  object \n",
            " 4   state              257673 non-null  object \n",
            " 5   spkts              257673 non-null  int64  \n",
            " 6   dpkts              257673 non-null  int64  \n",
            " 7   sbytes             257673 non-null  int64  \n",
            " 8   dbytes             257673 non-null  int64  \n",
            " 9   rate               257673 non-null  float64\n",
            " 10  sttl               257673 non-null  int64  \n",
            " 11  dttl               257673 non-null  int64  \n",
            " 12  sload              257673 non-null  float64\n",
            " 13  dload              257673 non-null  float64\n",
            " 14  sloss              257673 non-null  int64  \n",
            " 15  dloss              257673 non-null  int64  \n",
            " 16  sinpkt             257673 non-null  float64\n",
            " 17  dinpkt             257673 non-null  float64\n",
            " 18  sjit               257673 non-null  float64\n",
            " 19  djit               257673 non-null  float64\n",
            " 20  swin               257673 non-null  int64  \n",
            " 21  stcpb              257673 non-null  int64  \n",
            " 22  dtcpb              257673 non-null  int64  \n",
            " 23  dwin               257673 non-null  int64  \n",
            " 24  tcprtt             257673 non-null  float64\n",
            " 25  synack             257673 non-null  float64\n",
            " 26  ackdat             257673 non-null  float64\n",
            " 27  smean              257673 non-null  int64  \n",
            " 28  dmean              257673 non-null  int64  \n",
            " 29  trans_depth        257673 non-null  int64  \n",
            " 30  response_body_len  257673 non-null  int64  \n",
            " 31  ct_srv_src         257673 non-null  int64  \n",
            " 32  ct_state_ttl       257673 non-null  int64  \n",
            " 33  ct_dst_ltm         257673 non-null  int64  \n",
            " 34  ct_src_dport_ltm   257673 non-null  int64  \n",
            " 35  ct_dst_sport_ltm   257673 non-null  int64  \n",
            " 36  ct_dst_src_ltm     257673 non-null  int64  \n",
            " 37  is_ftp_login       257673 non-null  int64  \n",
            " 38  ct_ftp_cmd         257673 non-null  int64  \n",
            " 39  ct_flw_http_mthd   257673 non-null  int64  \n",
            " 40  ct_src_ltm         257673 non-null  int64  \n",
            " 41  ct_srv_dst         257673 non-null  int64  \n",
            " 42  is_sm_ips_ports    257673 non-null  int64  \n",
            " 43  attack_cat         257673 non-null  object \n",
            "dtypes: float64(11), int64(29), object(4)\n",
            "memory usage: 86.5+ MB\n"
          ]
        }
      ],
      "source": [
        "X.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 297,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQ7wPlSO1oMO",
        "outputId": "c90d4973-16f4-4afe-8e41-6c1466de73b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['proto', 'service', 'state', 'attack_cat'], dtype='object')"
            ]
          },
          "execution_count": 297,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Getting object type features\n",
        "\n",
        "X.select_dtypes(exclude=['int64','float64']).columns "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 298,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9Ci8vG06oY-",
        "outputId": "832dcb92-23f6-4dde-a4bc-cda6ff840956"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "122182"
            ]
          },
          "execution_count": 298,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max(X['spkts'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 299,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1Ncaxfx3FGz",
        "outputId": "a835d26b-19e6-4bf2-e6fd-d9d66280c19e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "is_ftp_login: has 98.74065191153129% unique value\n",
            "ct_ftp_cmd: has 98.73987573397291% unique value\n",
            "is_sm_ips_ports: has 98.5726094701424% unique value\n"
          ]
        }
      ],
      "source": [
        "# Checking frequency of values in each column\n",
        "# Getting all feture values with frequency higher than 95\n",
        "\n",
        "drop_list = []\n",
        "for column in X.columns:\n",
        "    percentage = (max(X[column].value_counts())*100) / X.shape[0]\n",
        "    if percentage > 95:\n",
        "        print(f\"{column}: has {percentage}% unique value\")\n",
        "        drop_list.append(column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 300,
      "metadata": {
        "id": "dvqjslHJ3nmn"
      },
      "outputs": [],
      "source": [
        "# Drop features -> is_ftp_login, -> ct_ftp_cmd, -> is_sm_ips_ports\n",
        "\n",
        "X = X.drop(columns = drop_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 301,
      "metadata": {
        "id": "DLrAuAlm9sRE"
      },
      "outputs": [],
      "source": [
        "# full_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 302,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bk4cAcJp9uA8",
        "outputId": "8fa637e3-0b91-4bf7-f7d8-f86e26620f2e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 302,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Checking for NaN values\n",
        "X.isnull().any().any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 303,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzUdmkNd98e4",
        "outputId": "37265d25-0105-4e64-daf6-e09888574c45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['proto', 'service', 'state', 'attack_cat'], dtype='object')"
            ]
          },
          "execution_count": 303,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Getting categorical features\n",
        "\n",
        "object_cols = X.select_dtypes(exclude=['int64','float64']).columns\n",
        "object_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 304,
      "metadata": {
        "id": "F6Avbjtc_oNU"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encoding categorical features using LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "X[object_cols] = X[object_cols].apply(le.fit_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 305,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4n5LBHWnB_Dn",
        "outputId": "1e8b85a7-0e71-40fd-efc0-d6f54cca7862"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index([], dtype='object')"
            ]
          },
          "execution_count": 305,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Checking for categorical features\n",
        "\n",
        "X.select_dtypes(exclude=['int64','float64']).columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 306,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RfCLcyACzyT",
        "outputId": "61667d0b-2130-4569-f234-a8a9270e37be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 306,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Checking for categorical features\n",
        "\n",
        "(X.dtypes == 'object').any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 307,
      "metadata": {
        "id": "NrDCy1rvDFad"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "# Data normalizing using RobustScaler\n",
        "\n",
        "transformer = RobustScaler().fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 308,
      "metadata": {
        "id": "y0Lm10O9D-rw"
      },
      "outputs": [],
      "source": [
        "robust_df = pd.DataFrame(transformer, columns = X.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 309,
      "metadata": {
        "id": "lrnhWxIV3Pbo"
      },
      "outputs": [],
      "source": [
        "# robust_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 310,
      "metadata": {
        "id": "UqKfUxTPD_5Q"
      },
      "outputs": [],
      "source": [
        "X = robust_df.drop(columns = ['dwin','id'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 311,
      "metadata": {
        "id": "uHMBIqL23Zru"
      },
      "outputs": [],
      "source": [
        "# Splitting dataset \n",
        "\n",
        "x_train = X[:len(train)]\n",
        "y_train = y[:len(train)]\n",
        "\n",
        "x_test = X[len(train):]\n",
        "y_test = y[len(train):]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAAal6-vKmFM"
      },
      "source": [
        "### Conditional GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 312,
      "metadata": {
        "id": "Swo-XGkeEtut"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch.utils.data as data_utils\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 313,
      "metadata": {
        "id": "CQsw0zsT5Qb9"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Converting data to tensor\n",
        "X_train = torch.Tensor(x_train.to_numpy())\n",
        "X_test = torch.Tensor(x_test.to_numpy())\n",
        "\n",
        "Y_train = torch.tensor(y_train.to_numpy(dtype=int), dtype=torch.int64)\n",
        "Y_test = torch.tensor(y_test.to_numpy(dtype=int), dtype=torch.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 314,
      "metadata": {
        "id": "36nakqMK5QZD"
      },
      "outputs": [],
      "source": [
        "# Data loading \n",
        "train_loader = DataLoader(TensorDataset(X_train, Y_train), batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(X_test, Y_test), batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 315,
      "metadata": {
        "id": "7k5iRGCC5QWg"
      },
      "outputs": [],
      "source": [
        "# Conditional Generative Adversarial Network (cGAN) model\n",
        "# Generator class\n",
        "class Generator(nn.Module):\n",
        "    \n",
        "  def __init__(self, z_size=100, h_dim=128):\n",
        "    super(Generator, self).__init__()\n",
        "    \n",
        "    self.g_model = nn.Sequential(\n",
        "      nn.Linear(z_size, h_dim),\n",
        "      nn.Linear(h_dim, h_dim*2),\n",
        "      nn.ReLU(True),\n",
        "      nn.Linear(h_dim*2, h_dim*4),\n",
        "      nn.ReLU(True),\n",
        "      nn.Linear(h_dim*4, 39)\n",
        "    )\n",
        "    \n",
        "    # self.generator.apply(self.__init_weights)\n",
        "    self.__init_weights(self.g_model)\n",
        "\n",
        "  def forward(self, z, y):\n",
        "    y = F.one_hot(y, num_classes=10)\n",
        "    \n",
        "    z = torch.cat((z, y), 1)\n",
        "    x = self.g_model(z)\n",
        "    \n",
        "    return x\n",
        "  \n",
        "  def __init_weights(self,m):\n",
        "    #Init the weights (optional)\n",
        "    if type(m) == nn.Linear:\n",
        "      torch.nn.init.xavier_uniform_(m.weight)\n",
        "      m.bias.data.fill_(0.01)\n",
        "      \n",
        "# Discriminator class\n",
        "class Discriminator(nn.Module):\n",
        "\n",
        "  def __init__(self, h_dim=128):\n",
        "    super(Discriminator, self).__init__()\n",
        "    \n",
        "    self.d_model = nn.Sequential(\n",
        "      nn.Linear(49, h_dim*4),\n",
        "      nn.Linear(h_dim*4, h_dim*2),\n",
        "      nn.LeakyReLU(inplace=True),\n",
        "      nn.Linear(h_dim*2, h_dim),\n",
        "      nn.LeakyReLU(inplace=True),\n",
        "      nn.Linear(h_dim, 1),\n",
        "      nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "    self.__init_weights(self.d_model)\n",
        "    # self.discriminator.apply(self.__init_weights)\n",
        "\n",
        "  def forward(self, x, y):\n",
        "\n",
        "    y = F.one_hot(y, num_classes=10)\n",
        "    x = torch.cat((x, y), 1)\n",
        "    x = self.d_model(x)\n",
        "    \n",
        "    return x\n",
        "  \n",
        "  def __init_weights(self,m):\n",
        " \n",
        "    if type(m) == nn.Linear:\n",
        "      torch.nn.init.xavier_uniform_(m.weight)\n",
        "      m.bias.data.fill_(0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 316,
      "metadata": {
        "id": "diW0u6505QTb"
      },
      "outputs": [],
      "source": [
        "def real_loss(d_out):\n",
        "  \n",
        "    batch_size = d_out.size(0)\n",
        "    labels = torch.FloatTensor(batch_size).uniform_(0.9, 1).to(device)\n",
        "    \n",
        "    loss_fn = nn.BCELoss()\n",
        "    \n",
        "    loss = loss_fn(d_out.squeeze(), labels)\n",
        "    return loss\n",
        "\n",
        "def fake_loss(d_out):\n",
        "    \n",
        "    batch_size = d_out.size(0)\n",
        "    labels = torch.FloatTensor(batch_size).uniform_(0, 0.1).to(device)\n",
        "    \n",
        "    loss_fn = nn.BCELoss()\n",
        "    \n",
        "    loss = loss_fn(d_out.squeeze(), labels)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 317,
      "metadata": {
        "id": "IBsyQ9KG5QQi"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-4\n",
        "eps = 1e-9\n",
        "\n",
        "G = Generator().to(device)\n",
        "D = Discriminator().to(device)\n",
        "\n",
        "g_optimizer = torch.optim.RMSprop(G.parameters(), lr=learning_rate, eps=eps)\n",
        "d_optimizer = torch.optim.RMSprop(D.parameters(), lr=learning_rate, eps=eps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 319,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06BpGc7W5QLF",
        "outputId": "62aa3fe6-e1b1-4822-e5f1-57c26834651c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch [1/100], d_loss: 0.9196 | g_loss: 1.3055\n",
            "epoch [2/100], d_loss: 0.8940 | g_loss: 1.3002\n",
            "epoch [3/100], d_loss: 1.4531 | g_loss: 1.6703\n",
            "epoch [4/100], d_loss: 0.9184 | g_loss: 1.3136\n",
            "epoch [5/100], d_loss: 0.8509 | g_loss: 1.7736\n",
            "epoch [6/100], d_loss: 1.0645 | g_loss: 1.7184\n",
            "epoch [7/100], d_loss: 1.0939 | g_loss: 1.3125\n",
            "epoch [8/100], d_loss: 1.0098 | g_loss: 1.4511\n",
            "epoch [9/100], d_loss: 0.7683 | g_loss: 1.7462\n",
            "epoch [10/100], d_loss: 1.3289 | g_loss: 1.1777\n",
            "epoch [11/100], d_loss: 0.9603 | g_loss: 1.5268\n",
            "epoch [12/100], d_loss: 0.9676 | g_loss: 1.8301\n",
            "epoch [13/100], d_loss: 1.1452 | g_loss: 1.9160\n",
            "epoch [14/100], d_loss: 0.7565 | g_loss: 1.8610\n",
            "epoch [15/100], d_loss: 0.9324 | g_loss: 1.6378\n",
            "epoch [16/100], d_loss: 1.3895 | g_loss: 2.0963\n",
            "epoch [17/100], d_loss: 0.8784 | g_loss: 1.7823\n",
            "epoch [18/100], d_loss: 1.0552 | g_loss: 1.7201\n",
            "epoch [19/100], d_loss: 0.7755 | g_loss: 1.7582\n",
            "epoch [20/100], d_loss: 0.7384 | g_loss: 2.0835\n",
            "epoch [21/100], d_loss: 1.0354 | g_loss: 1.9678\n",
            "epoch [22/100], d_loss: 0.9503 | g_loss: 1.8365\n",
            "epoch [23/100], d_loss: 0.8502 | g_loss: 1.6524\n",
            "epoch [24/100], d_loss: 0.9783 | g_loss: 1.8394\n",
            "epoch [25/100], d_loss: 1.1778 | g_loss: 1.7114\n",
            "epoch [26/100], d_loss: 0.9083 | g_loss: 1.9285\n",
            "epoch [27/100], d_loss: 0.9369 | g_loss: 1.8651\n",
            "epoch [28/100], d_loss: 0.9000 | g_loss: 1.9472\n",
            "epoch [29/100], d_loss: 1.0274 | g_loss: 1.3638\n",
            "epoch [30/100], d_loss: 0.7419 | g_loss: 1.6823\n",
            "epoch [31/100], d_loss: 0.8858 | g_loss: 2.0699\n",
            "epoch [32/100], d_loss: 0.6821 | g_loss: 2.0767\n",
            "epoch [33/100], d_loss: 0.9456 | g_loss: 1.4739\n",
            "epoch [34/100], d_loss: 0.8456 | g_loss: 1.7231\n",
            "epoch [35/100], d_loss: 0.8125 | g_loss: 1.6252\n",
            "epoch [36/100], d_loss: 0.8457 | g_loss: 1.9732\n",
            "epoch [37/100], d_loss: 0.8291 | g_loss: 1.8373\n",
            "epoch [38/100], d_loss: 1.2830 | g_loss: 1.4734\n",
            "epoch [39/100], d_loss: 1.0035 | g_loss: 2.2955\n",
            "epoch [40/100], d_loss: 0.9583 | g_loss: 1.8130\n",
            "epoch [41/100], d_loss: 0.7141 | g_loss: 1.8666\n",
            "epoch [42/100], d_loss: 1.1007 | g_loss: 1.8742\n",
            "epoch [43/100], d_loss: 0.8810 | g_loss: 1.6583\n",
            "epoch [44/100], d_loss: 0.7820 | g_loss: 2.2278\n",
            "epoch [45/100], d_loss: 0.9519 | g_loss: 1.7392\n",
            "epoch [46/100], d_loss: 1.0247 | g_loss: 2.0000\n",
            "epoch [47/100], d_loss: 0.7386 | g_loss: 2.3287\n",
            "epoch [48/100], d_loss: 1.1193 | g_loss: 1.8313\n",
            "epoch [49/100], d_loss: 1.4258 | g_loss: 2.1646\n",
            "epoch [50/100], d_loss: 1.5439 | g_loss: 1.7566\n",
            "epoch [51/100], d_loss: 0.7016 | g_loss: 2.0412\n",
            "epoch [52/100], d_loss: 1.0518 | g_loss: 2.1605\n",
            "epoch [53/100], d_loss: 0.7195 | g_loss: 2.3090\n",
            "epoch [54/100], d_loss: 0.7420 | g_loss: 2.3474\n",
            "epoch [55/100], d_loss: 0.9065 | g_loss: 2.0699\n",
            "epoch [56/100], d_loss: 1.3006 | g_loss: 2.4657\n",
            "epoch [57/100], d_loss: 0.7253 | g_loss: 2.1227\n",
            "epoch [58/100], d_loss: 0.7570 | g_loss: 2.2155\n",
            "epoch [59/100], d_loss: 0.8080 | g_loss: 2.3225\n",
            "epoch [60/100], d_loss: 1.2898 | g_loss: 2.4453\n",
            "epoch [61/100], d_loss: 0.8469 | g_loss: 2.8376\n",
            "epoch [62/100], d_loss: 0.7518 | g_loss: 2.1106\n",
            "epoch [63/100], d_loss: 0.7414 | g_loss: 1.6553\n",
            "epoch [64/100], d_loss: 0.6986 | g_loss: 2.4041\n",
            "epoch [65/100], d_loss: 0.7407 | g_loss: 2.6824\n",
            "epoch [66/100], d_loss: 0.7149 | g_loss: 2.2028\n",
            "epoch [67/100], d_loss: 0.8157 | g_loss: 2.0377\n",
            "epoch [68/100], d_loss: 0.9801 | g_loss: 2.6939\n",
            "epoch [69/100], d_loss: 0.7357 | g_loss: 2.3659\n",
            "epoch [70/100], d_loss: 0.7368 | g_loss: 2.2110\n",
            "epoch [71/100], d_loss: 0.9842 | g_loss: 2.0298\n",
            "epoch [72/100], d_loss: 0.8376 | g_loss: 1.9640\n",
            "epoch [73/100], d_loss: 0.8725 | g_loss: 2.2080\n",
            "epoch [74/100], d_loss: 0.7900 | g_loss: 2.5480\n",
            "epoch [75/100], d_loss: 0.8440 | g_loss: 2.2995\n",
            "epoch [76/100], d_loss: 0.7914 | g_loss: 2.2286\n",
            "epoch [77/100], d_loss: 0.9554 | g_loss: 2.0068\n",
            "epoch [78/100], d_loss: 1.4631 | g_loss: 2.7214\n",
            "epoch [79/100], d_loss: 1.2255 | g_loss: 2.4810\n",
            "epoch [80/100], d_loss: 0.7508 | g_loss: 2.1853\n",
            "epoch [81/100], d_loss: 1.0224 | g_loss: 1.9555\n",
            "epoch [82/100], d_loss: 1.1999 | g_loss: 2.0898\n",
            "epoch [83/100], d_loss: 0.8116 | g_loss: 2.3041\n",
            "epoch [84/100], d_loss: 1.0648 | g_loss: 1.7246\n",
            "epoch [85/100], d_loss: 1.0306 | g_loss: 2.0829\n",
            "epoch [86/100], d_loss: 1.3546 | g_loss: 2.0471\n",
            "epoch [87/100], d_loss: 0.8328 | g_loss: 1.9898\n",
            "epoch [88/100], d_loss: 1.5831 | g_loss: 2.5411\n",
            "epoch [89/100], d_loss: 0.7743 | g_loss: 2.6378\n",
            "epoch [90/100], d_loss: 0.7662 | g_loss: 2.4943\n",
            "epoch [91/100], d_loss: 1.0483 | g_loss: 2.0569\n",
            "epoch [92/100], d_loss: 0.9155 | g_loss: 2.2742\n",
            "epoch [93/100], d_loss: 0.8784 | g_loss: 2.3590\n",
            "epoch [94/100], d_loss: 1.0373 | g_loss: 2.5568\n",
            "epoch [95/100], d_loss: 1.4187 | g_loss: 2.6178\n",
            "epoch [96/100], d_loss: 0.8438 | g_loss: 2.1783\n",
            "epoch [97/100], d_loss: 1.0645 | g_loss: 2.3326\n",
            "epoch [98/100], d_loss: 1.1023 | g_loss: 2.2818\n",
            "epoch [99/100], d_loss: 0.7696 | g_loss: 1.9347\n",
            "epoch [100/100], d_loss: 0.7562 | g_loss: 1.7489\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 100\n",
        "z_size = 90\n",
        "\n",
        "losses = []\n",
        "\n",
        "# epoch training loop\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    for _, (X, y) in enumerate(train_loader):\n",
        "\n",
        "        batch_size = X.size(0)\n",
        "        z = np.random.uniform(-1, 1, size=(batch_size, z_size))\n",
        "        z = torch.from_numpy(z).float().to(device)\n",
        "        \n",
        "        # Discriminator on real and fake images\n",
        "        d_optimizer.zero_grad()\n",
        "        \n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        d_real = D(X, y)\n",
        "        d_loss = real_loss(d_real)\n",
        "        \n",
        "        g_fake = G(z, y)\n",
        "        \n",
        "        d_fake = D(g_fake, y)\n",
        "        d_loss = d_loss + fake_loss(d_fake)\n",
        "        \n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "\n",
        "        # Generator on real and fake images\n",
        "        g_optimizer.zero_grad()\n",
        "        \n",
        "        g_fake = G(z, y)\n",
        "        \n",
        "        g_loss = real_loss(D(g_fake, y))\n",
        "        \n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "            \n",
        "    print('epoch [{}/{}], d_loss: {:6.4f} | g_loss: {:6.4f}'.format(epoch + 1, num_epochs, d_loss.item(), g_loss.item()))\n",
        "    losses.append((d_loss.item(), g_loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 334,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdDwbjNAYbBY",
        "outputId": "34562019-249d-429c-f0d6-c0b6b89a799a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.91961777, 0.89403558, 1.45306993, 0.91836882, 0.85088539,\n",
              "        1.06447673, 1.09390175, 1.00982428, 0.7682991 , 1.32887363,\n",
              "        0.96032488, 0.96761698, 1.14524543, 0.75653231, 0.93237972,\n",
              "        1.38946748, 0.87840688, 1.05523026, 0.77554238, 0.73843646,\n",
              "        1.03541207, 0.95033801, 0.85016167, 0.97827101, 1.17779744,\n",
              "        0.90834665, 0.93691641, 0.89995015, 1.02743292, 0.74191725,\n",
              "        0.88575792, 0.68214643, 0.94558758, 0.84564155, 0.81247371,\n",
              "        0.84573877, 0.82907581, 1.2830112 , 1.00352192, 0.95833874,\n",
              "        0.71411723, 1.10066366, 0.88098454, 0.78203034, 0.95191896,\n",
              "        1.02465141, 0.73862112, 1.119344  , 1.42577398, 1.54393733,\n",
              "        0.70163846, 1.0517602 , 0.71950454, 0.74195486, 0.90648121,\n",
              "        1.30059826, 0.72531605, 0.75700593, 0.80796003, 1.28977561,\n",
              "        0.84689653, 0.751755  , 0.74139398, 0.69864553, 0.74069077,\n",
              "        0.71486527, 0.81568271, 0.98009199, 0.73567581, 0.73682582,\n",
              "        0.98417956, 0.8375994 , 0.87252533, 0.79001498, 0.84395152,\n",
              "        0.79135132, 0.95537019, 1.46308446, 1.22553992, 0.75082344,\n",
              "        1.02243233, 1.19990826, 0.81160927, 1.06480396, 1.03055334,\n",
              "        1.35459983, 0.83284223, 1.5830884 , 0.77432036, 0.76618588,\n",
              "        1.04831684, 0.9155367 , 0.87842602, 1.03728795, 1.41873133,\n",
              "        0.84381896, 1.06450152, 1.10229123, 0.76955235, 0.75621605],\n",
              "       [1.30550551, 1.30017257, 1.67032897, 1.31362557, 1.7735647 ,\n",
              "        1.71843994, 1.3125422 , 1.45112979, 1.74615467, 1.17769909,\n",
              "        1.52680647, 1.83007455, 1.91599357, 1.86100185, 1.63777137,\n",
              "        2.09632063, 1.78225422, 1.72014606, 1.75821364, 2.08348465,\n",
              "        1.96779978, 1.83651412, 1.65243363, 1.83940971, 1.71139705,\n",
              "        1.92851949, 1.86509037, 1.94716871, 1.36378467, 1.68233407,\n",
              "        2.06986284, 2.07669878, 1.47385776, 1.72308648, 1.62515664,\n",
              "        1.97321093, 1.83734488, 1.47338545, 2.29547834, 1.8129828 ,\n",
              "        1.86657906, 1.87416756, 1.65826499, 2.2278254 , 1.73915195,\n",
              "        2.00000787, 2.3286922 , 1.83127713, 2.16458249, 1.75661635,\n",
              "        2.04124546, 2.16045046, 2.30895019, 2.34742928, 2.06987548,\n",
              "        2.46568489, 2.12271619, 2.21552515, 2.32249427, 2.44532061,\n",
              "        2.83756995, 2.11059618, 1.65532231, 2.4040885 , 2.68237948,\n",
              "        2.20284629, 2.03768969, 2.6938796 , 2.36589575, 2.2109952 ,\n",
              "        2.02982306, 1.96402144, 2.20800328, 2.54803824, 2.29948497,\n",
              "        2.2285707 , 2.00677037, 2.72144771, 2.48103166, 2.18528628,\n",
              "        1.95553672, 2.08978486, 2.30410147, 1.72464347, 2.08291459,\n",
              "        2.04705858, 1.98979306, 2.54111528, 2.63780665, 2.49429917,\n",
              "        2.05689669, 2.27421474, 2.35898471, 2.55681539, 2.6178062 ,\n",
              "        2.17833757, 2.33259702, 2.28181601, 1.93468535, 1.74885881]])"
            ]
          },
          "execution_count": 334,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "losses = np.asarray(losses).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {
        "id": "HnEYJptC--B0"
      },
      "outputs": [],
      "source": [
        "# !pip3 install interpret"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC8aQ6sUKxBX"
      },
      "source": [
        "### Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 336,
      "metadata": {
        "id": "G1ojbLVyPTL1"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from interpret.glassbox import ExplainableBoostingClassifier\n",
        "from sklearn.metrics import f1_score, classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 324,
      "metadata": {
        "id": "RoCDiWWt-6_w"
      },
      "outputs": [],
      "source": [
        "# Build NN Classifier\n",
        "\n",
        "class nn_classifier(nn.Module):\n",
        "    \n",
        "  def __init__(self, i_size=39, h_dim=15, n_classes=10):\n",
        "    super(nn_classifier, self).__init__()\n",
        "    \n",
        "    self.classifier_model = nn.Sequential(\n",
        "      nn.Linear(i_size, h_dim),\n",
        "      nn.ReLU(True),\n",
        "      nn.Linear(h_dim, n_classes)\n",
        "    )\n",
        "    \n",
        "    self.__init_weights(self.classifier_model)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    out = self.classifier_model(x)\n",
        "    return out\n",
        "  \n",
        "  def __init_weights(self,m):\n",
        "\n",
        "    if type(m) == nn.Linear:\n",
        "      torch.nn.init.xavier_uniform_(m.weight)\n",
        "      m.bias.data.fill_(0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 325,
      "metadata": {
        "id": "0_dClqZd_LQb"
      },
      "outputs": [],
      "source": [
        "# Train NN Classifier\n",
        "def nn_classifier_train(model, train_loader, num_epochs = 20):\n",
        "    learning_rate = 1e-4\n",
        "    eps = 1e-9\n",
        "    \n",
        "    optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate, eps=eps)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        for X, y in train_loader:\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            # forward\n",
        "            output = model(X)\n",
        "            loss = criterion(output, y)\n",
        "            \n",
        "            # backward\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        # log\n",
        "        print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, num_epochs, loss.item()))\n",
        "        \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 326,
      "metadata": {
        "id": "fcWOObxQ_NwR"
      },
      "outputs": [],
      "source": [
        "rfc = RandomForestClassifier(max_depth=50, n_jobs=-1)\n",
        "ebc = ExplainableBoostingClassifier(max_bins=2, n_jobs=-1, interactions=0, max_leaves=50)\n",
        "nnc = nn_classifier().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 327,
      "metadata": {
        "id": "EHHTspVq_RcG"
      },
      "outputs": [],
      "source": [
        "arr_x_train = x_train.values\n",
        "arr_y_train = y_train.values\n",
        "\n",
        "arr_x_test = x_test.values\n",
        "arr_y_test = y_test.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 329,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9tCEANC_ifO",
        "outputId": "0041d82f-7a8f-40dc-e718-c225f5a5023c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch [1/20], loss:0.0510\n",
            "epoch [2/20], loss:0.0617\n",
            "epoch [3/20], loss:0.1137\n",
            "epoch [4/20], loss:0.1032\n",
            "epoch [5/20], loss:0.0464\n",
            "epoch [6/20], loss:0.0168\n",
            "epoch [7/20], loss:0.0227\n",
            "epoch [8/20], loss:0.0646\n",
            "epoch [9/20], loss:0.0111\n",
            "epoch [10/20], loss:0.0412\n",
            "epoch [11/20], loss:0.2808\n",
            "epoch [12/20], loss:0.0317\n",
            "epoch [13/20], loss:0.0786\n",
            "epoch [14/20], loss:0.0145\n",
            "epoch [15/20], loss:0.0663\n",
            "epoch [16/20], loss:0.0235\n",
            "epoch [17/20], loss:0.1158\n",
            "epoch [18/20], loss:0.0734\n",
            "epoch [19/20], loss:0.0134\n",
            "epoch [20/20], loss:0.0662\n",
            "--------------------\n",
            "F1 Score for RandomForestClassifier: 0.9998859397889113\n",
            "F1 Score for ExplainableBoostingClassifier: 0.9998859397889113\n",
            "Score for Neural Nets Classifier: 0.9832025165485135\n"
          ]
        }
      ],
      "source": [
        "nn_classifier_train(nnc, train_loader)\n",
        "\n",
        "outputs = nnc(X_test.to(device))\n",
        "nnc_y_pred = torch.max(outputs.data, 1)[1].cpu().detach().numpy()\n",
        "\n",
        "# RandomForestClassifier\n",
        "rfc.fit(arr_x_train,arr_y_train)\n",
        "rfc_y_pred = rfc.predict(arr_x_test)\n",
        "\n",
        "# ExplainableBoostingClassifier\n",
        "ebc.fit(arr_x_train,arr_y_train)\n",
        "ebc_y_pred = rfc.predict(arr_x_test)\n",
        "\n",
        "# Scores\n",
        "rfc_score = f1_score(arr_y_test, rfc_y_pred, average=\"weighted\")\n",
        "ebc_score =  f1_score(arr_y_test, ebc_y_pred, average=\"weighted\")\n",
        "nnc_score = f1_score(arr_y_test, nnc_y_pred, average=\"weighted\")\n",
        "\n",
        "print('-'*20)\n",
        "print(f'F1 Score for RandomForestClassifier: {rfc_score}')\n",
        "print(f'F1 Score for ExplainableBoostingClassifier: {ebc_score}')\n",
        "print(f'Score for Neural Nets Classifier: {nnc_score}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 340,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lB0V0PLgWoOI",
        "outputId": "785add04-7884-4382-9cf7-fae7b32bb577"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------\n",
            "RandomForestClassifier classification report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56000\n",
            "           1       1.00      1.00      1.00    119341\n",
            "\n",
            "    accuracy                           1.00    175341\n",
            "   macro avg       1.00      1.00      1.00    175341\n",
            "weighted avg       1.00      1.00      1.00    175341\n",
            "\n",
            "------------------------------------------------------------\n",
            "ExplainableBoostingClassifier classification report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56000\n",
            "           1       1.00      1.00      1.00    119341\n",
            "\n",
            "    accuracy                           1.00    175341\n",
            "   macro avg       1.00      1.00      1.00    175341\n",
            "weighted avg       1.00      1.00      1.00    175341\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('-'*60)\n",
        "print('RandomForestClassifier classification report\\n')\n",
        "print(classification_report(arr_y_test, rfc_y_pred))\n",
        "print('-'*60)\n",
        "print('ExplainableBoostingClassifier classification report\\n')\n",
        "print(classification_report(arr_y_test, ebc_y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5vxaTomavL6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MUj3d2QbiD0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled1 (1).ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
